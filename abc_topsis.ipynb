{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6AHmyKjBO7p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import joblib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import pickle\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr9mlzk5BO7q"
      },
      "outputs": [],
      "source": [
        "# Better rendering\n",
        "from IPython.core.display import HTML\n",
        "HTML(\"<style>.rendered_html th {max-width: 120px;}</style>\")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# settings to display all columns\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrxzh2Y8BO7q"
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "# Specify the path to your CSV file\n",
        "brand1_csv = \"/Users/galuhprisillia/PycharmProjects/forecasting/brand1.csv\"\n",
        "brand2_csv = \"/Users/galuhprisillia/PycharmProjects/forecasting/brand2.csv\"\n",
        "brand3_csv = \"/Users/galuhprisillia/PycharmProjects/forecasting/brand3.csv\"\n",
        "brand4_csv = \"/Users/galuhprisillia/PycharmProjects/forecasting/brand4.csv\"\n",
        "# Display the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgwpbXBUBO7q"
      },
      "outputs": [],
      "source": [
        "# df_brand1 = pd.read_csv(brand1_csv)\n",
        "df_brand1 = pd.read_csv(brand1_csv)\n",
        "df_brand2 = pd.read_csv(brand2_csv)\n",
        "df_brand3 = pd.read_csv(brand3_csv)\n",
        "df_brand4 = pd.read_csv(brand4_csv)\n",
        "\n",
        "df = pd.concat([df_brand1, df_brand2, df_brand3, df_brand4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5EcU2MVBO7r"
      },
      "outputs": [],
      "source": [
        "# change date to datetime\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# rename default_code column to product_id\n",
        "df = df.rename(columns={'default_code': 'product_id'})\n",
        "# make a new column buy_quantity and sell_quantity\n",
        "df['buy_quantity'] = df['product_qty'].apply(lambda x: x if x > 0 else 0)\n",
        "df['sell_quantity'] = df['product_qty'].apply(lambda x: x if x < 0 else 0)\n",
        "\n",
        "# make buy_quntity positive\n",
        "df['buy_quantity'] = df['buy_quantity'].apply(lambda x: abs(x))\n",
        "df['sell_quantity'] = df['sell_quantity'].apply(lambda x: abs(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdnjhkUdBO7r"
      },
      "outputs": [],
      "source": [
        "# drop if is_pack is True\n",
        "df = df[df.is_pack == False]\n",
        "\n",
        "# drop reference column\n",
        "df = df.drop(columns=['reference'])\n",
        "\n",
        "# drop is_pack column\n",
        "df = df.drop(columns=['is_pack'])\n",
        "\n",
        "df = df.drop(columns=['product_qty'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLjIUeeGBO7r"
      },
      "outputs": [],
      "source": [
        "# sort the dataframe by product_id, and date and reset index\n",
        "df_filter = df.sort_values(by=['product_id', 'date'])\n",
        "\n",
        "df_filter = df_filter.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1hxAaEGBO7r"
      },
      "outputs": [],
      "source": [
        "df_filter.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45IENyy9BO7r"
      },
      "outputs": [],
      "source": [
        "df_filter.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Id12RLTRBO7r"
      },
      "outputs": [],
      "source": [
        "# filter the dataframe by date 2023-01-01 to 2023-12-12\n",
        "df_filter = df_filter[(df_filter['date'] >= '2023-01-01') & (df_filter['date'] <= '2023-12-12')]\n",
        "df_filter = df_filter.reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1VM_D2EBO7s"
      },
      "outputs": [],
      "source": [
        "df_filter.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cFfgJW8BO7s"
      },
      "outputs": [],
      "source": [
        "# warehouse cost = 2% of the product price >> annual cost\n",
        "# product price = 70% of the product list price\n",
        "# lead time random, depends on the transportation, we will random using (2,3,4) days\n",
        "\n",
        "# make a new column product_price\n",
        "df_filter['product_price'] = df_filter['list_price'] * 0.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A9N4PEHBO7s"
      },
      "outputs": [],
      "source": [
        "df_filter.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOuxOE9FBO7s"
      },
      "outputs": [],
      "source": [
        "# ABC Analysis\n",
        "# make it annual, and group by product_id, make atotal of buy_quantity, sell_quantity, product_price, and warehouse_cost\n",
        "# use TOPSIS to rank the product_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBp5Az--BO7s"
      },
      "outputs": [],
      "source": [
        "df_filter.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZNjMqgjBO7s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "product_ids = []\n",
        "annual_buy_quantities = []\n",
        "annual_sell_quantities = []\n",
        "annual_product_prices = []\n",
        "annual_unit_costs = []\n",
        "\n",
        "# per product_id utilities cost = 48000000/lenght of product_id\n",
        "utilities_cost = 48000000/len(df_filter['product_id'].unique())\n",
        "\n",
        "for product_id in df_filter['product_id'].unique():\n",
        "    product_data = df_filter[df_filter['product_id'] == product_id]\n",
        "\n",
        "    # calculate annual buy_quantity\n",
        "    annual_buy_quantity = product_data['buy_quantity'].sum()\n",
        "    # calculate annual sell_quantity\n",
        "    annual_sell_quantity = product_data['sell_quantity'].sum()\n",
        "    # calculate annual product_price using average price\n",
        "    average_product_price = product_data['product_price'].mean()\n",
        "\n",
        "    # annual_unit_cost = utilities_cost/annual_buy_quantity\n",
        "    annual_unit_cost = utilities_cost/annual_buy_quantity\n",
        "\n",
        "    # append the result to the list\n",
        "    product_ids.append(product_id)\n",
        "    annual_buy_quantities.append(annual_buy_quantity)\n",
        "    annual_sell_quantities.append(annual_sell_quantity)\n",
        "    annual_product_prices.append(average_product_price)\n",
        "    annual_unit_costs.append(annual_unit_cost)\n",
        "\n",
        "# make a new dataframe\n",
        "result_df = pd.DataFrame({\n",
        "    'product_id': product_ids,\n",
        "    'annual_buy_quantity': annual_buy_quantities,\n",
        "    'annual_sell_quantity': annual_sell_quantities,\n",
        "    'annual_product_price': annual_product_prices,\n",
        "    'annual_unit_cost': annual_unit_costs\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwJMwfKJBO7s"
      },
      "outputs": [],
      "source": [
        "result_df['product_id'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AO31dqNBO7t"
      },
      "outputs": [],
      "source": [
        "# add new column lead_time with random value (2,3,4)\n",
        "result_df['lead_time'] = np.random.randint(2, 5, result_df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95tIprxABO7t"
      },
      "outputs": [],
      "source": [
        "result_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aZUyJVVBO7t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming result_df is your DataFrame\n",
        "# You can also use result_df.copy() to create a new DataFrame if you want to keep the original unchanged\n",
        "result_df = result_df[~result_df.isin([np.inf, -np.inf]).any(axis=1)]\n",
        "\n",
        "# reset the index\n",
        "result_df = result_df.reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhiaowg4BO7t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming result_df is your DataFrame\n",
        "# You can also use result_df.copy() to create a new DataFrame if you want to keep the original unchanged\n",
        "df_renamed = result_df.copy()\n",
        "\n",
        "# # Rename the 'product_id' column based on the current index\n",
        "# df_renamed['product_id'] = 'item ' + (df_renamed.index + 1).astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4Gbbcg2BO7t"
      },
      "outputs": [],
      "source": [
        "df_renamed.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtDlJmaABO7t"
      },
      "outputs": [],
      "source": [
        "df_renamed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERNpedY_BO7t"
      },
      "outputs": [],
      "source": [
        "df_renamed_2 = df_renamed.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWHI3tlzBO7u"
      },
      "outputs": [],
      "source": [
        "sum([0.45, 0.30, 0.125, 0.125])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqFJ5l9SBO7u"
      },
      "outputs": [],
      "source": [
        "# TOPSIS Analys using equal weighta\n",
        "# weight by the proffesional (Galuh)\n",
        "weights =  [0.45, 0.30, 0.125, 0.125]\n",
        "normalized_weights = [w / sum(weights) for w in weights]\n",
        "\n",
        "#annual_sell_quatity, annual_product_price, annual_unit_cost, and lead_time\n",
        "\n",
        "# Required Libraries\n",
        "\n",
        "# normalize the matrix using the weight given by the proffesional\n",
        "def normalize(dataset, nCol, weights):\n",
        "    for i in range(1, nCol):\n",
        "        temp = 0\n",
        "        # Calculating Root of Sum of squares of a particular column\n",
        "        for j in range(len(dataset)):\n",
        "            temp = temp + dataset.iloc[j, i]**2\n",
        "        temp = temp**0.5\n",
        "        # Weighted Normalizing a element\n",
        "        for j in range(len(dataset)):\n",
        "            dataset.iat[j, i] = (dataset.iloc[j, i] / temp)*weights[i-1]\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKKnj4nNBO7u"
      },
      "outputs": [],
      "source": [
        "# drop annual_buy_quantity column\n",
        "df_renamed = df_renamed.drop(columns=['annual_buy_quantity'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kttYTk1DBO7u"
      },
      "outputs": [],
      "source": [
        "df_renamed_normalized = normalize(df_renamed, 5, weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cj0lAG4HBO7u"
      },
      "outputs": [],
      "source": [
        "df_renamed_normalized.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43lMCZvHBO7u"
      },
      "outputs": [],
      "source": [
        "# calculate ideal best and ideal worst\n",
        "\n",
        "def calc_values(dataset, nCol, impact):\n",
        "    p_sln = (dataset.max().values)[1:]\n",
        "    n_sln = (dataset.min().values)[1:]\n",
        "    for i in range(1, nCol):\n",
        "        if impact[i-1] == '-':\n",
        "            p_sln[i-1], n_sln[i-1] = n_sln[i-1], p_sln[i-1]\n",
        "    return p_sln, n_sln"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie5eDTLJBO7u"
      },
      "outputs": [],
      "source": [
        "temp_dataset = df_renamed_normalized.copy()\n",
        "nCol = 4\n",
        "impact = ['+', '+', '+', '+']\n",
        "\n",
        "# Calculating positive and negative values\n",
        "p_sln, n_sln = calc_values(temp_dataset, nCol, impact)\n",
        "\n",
        "# calculating topsis score\n",
        "score = [] # Topsis score\n",
        "pp = [] # distance positive\n",
        "nn = [] # distance negative\n",
        "\n",
        "\n",
        "# Calculating distances and Topsis score for each row\n",
        "for i in range(len(temp_dataset)):\n",
        "    temp_p, temp_n = 0, 0\n",
        "    for j in range(1, nCol):\n",
        "        temp_p = temp_p + (p_sln[j-1] - temp_dataset.iloc[i, j])**2\n",
        "        temp_n = temp_n + (n_sln[j-1] - temp_dataset.iloc[i, j])**2\n",
        "    temp_p, temp_n = temp_p**0.5, temp_n**0.5\n",
        "    temp_score = temp_n/(temp_p + temp_n)\n",
        "    score.append(temp_score)\n",
        "    nn.append(temp_n)\n",
        "    pp.append(temp_p)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE_K4KPTBO7v"
      },
      "outputs": [],
      "source": [
        "# Appending new columns in dataset\n",
        "\n",
        "df_renamed['distance positive'] = pp\n",
        "df_renamed['distance negative'] = nn\n",
        "# normalize the topsis score so that it is sum of 1\n",
        "score = score/sum(score)\n",
        "df_renamed['Topsis Score'] = score\n",
        "\n",
        "# calculating the rank according to topsis score\n",
        "df_renamed['Rank'] = (df_renamed['Topsis Score'].rank(method='max', ascending=False))\n",
        "df_renamed = df_renamed.astype({\"Rank\": int})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKu-EV85BO7v"
      },
      "outputs": [],
      "source": [
        "df_renamed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfccbhysBO7v"
      },
      "outputs": [],
      "source": [
        "# sort the dataset by Rank\n",
        "df_renamed = df_renamed.sort_values(by=['Rank'])\n",
        "\n",
        "# reset the index\n",
        "df_renamed = df_renamed.reset_index(drop=True)\n",
        "df_renamed.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAgDVEsnBO7v"
      },
      "outputs": [],
      "source": [
        "# make new column cum_sum and cum_perc\n",
        "# cum_sum is cumulative sum of the topsis score\n",
        "df_renamed['cum_sum'] = df_renamed['Topsis Score'].cumsum()\n",
        "# cum_perc is percentage of the cum_sum\n",
        "df_renamed['cum_perc'] = 100*df_renamed['cum_sum']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2mTT6jXBO7v"
      },
      "outputs": [],
      "source": [
        "df_renamed.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJayVE7WBO7v"
      },
      "outputs": [],
      "source": [
        "# sum onf topsis score\n",
        "df_renamed['Topsis Score'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jio63DzIBO7v"
      },
      "outputs": [],
      "source": [
        "# ABC Analysis for the topsis\n",
        "# if the cum_perc is <= 20% then A\n",
        "# if the cum_perc is <= 50% then B\n",
        "# and the rest is C\n",
        "\n",
        "# make a new column ABC\n",
        "df_renamed['ABC'] = df_renamed['cum_perc'].apply(lambda x: 'A' if x <= 20 else ('B' if x <= 50 else 'C'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJELdxeNBO7w"
      },
      "outputs": [],
      "source": [
        "df_renamed.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPGb6wcjBO7w"
      },
      "outputs": [],
      "source": [
        "df_renamed['ABC'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2ZSKdPKBO7x"
      },
      "outputs": [],
      "source": [
        "result_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoNExuPnBO7x"
      },
      "outputs": [],
      "source": [
        "result_df['class'] = result_df['product_id'].map(df_renamed.set_index('product_id')['ABC'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PYlHt8yBO7x"
      },
      "outputs": [],
      "source": [
        "result_df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtPwFbBKBO7x"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.scatterplot(data=result_df, x='annual_sell_quantity', y='annual_product_price', hue='class')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XZp4oToBO7x"
      },
      "outputs": [],
      "source": [
        "result_df['class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0lTLkFeBO7x"
      },
      "outputs": [],
      "source": [
        "# drop annual_buy_quantity column\n",
        "result_df = result_df.drop(columns=['annual_buy_quantity'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbnqMzEiBO7y"
      },
      "outputs": [],
      "source": [
        "result_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGcOSZIPBO7y"
      },
      "outputs": [],
      "source": [
        "result_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tL5_IwxBO7y"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "\n",
        "# Define columns\n",
        "X = result_df[['annual_sell_quantity', 'annual_product_price', 'annual_unit_cost', 'lead_time']]\n",
        "y = result_df['class']\n",
        "\n",
        "# Summarize class distribution\n",
        "print(\"Original class distribution:\", Counter(y))\n",
        "\n",
        "# Define oversampling strategy using a dictionary to maintain class proportions\n",
        "sampling_strategy = {'A': 200, 'B': 300, 'C': 500}\n",
        "oversample = RandomOverSampler(sampling_strategy=sampling_strategy)\n",
        "\n",
        "# Fit and apply the transform\n",
        "X_over, y_over = oversample.fit_resample(X, y)\n",
        "\n",
        "# Convert X_over to a DataFrame\n",
        "df_over = pd.DataFrame(X_over, columns=X.columns)\n",
        "\n",
        "# Add the 'class' column\n",
        "df_over['class'] = y_over\n",
        "\n",
        "# Summarize class distribution after oversampling\n",
        "print(\"Oversampled class distribution:\", Counter(y_over))\n",
        "\n",
        "df_over.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoTLEU1HBO7y"
      },
      "outputs": [],
      "source": [
        "# # change the class to numeric value\n",
        "# df_over['class'] = df_over['class'].apply(lambda x: 1 if x == 'A' else (2 if x == 'B' else 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HcaOT22BO7y"
      },
      "outputs": [],
      "source": [
        "df_over.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMAtkJ0PBO7y"
      },
      "outputs": [],
      "source": [
        "# plot the data after oversampling\n",
        "sns.scatterplot(data=df_over, x='annual_sell_quantity', y='annual_product_price', hue='class')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Caq-m9ahBO7z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmoPCH9wBO7z"
      },
      "outputs": [],
      "source": [
        "# using SVM and KNN to classify the data\n",
        "\n",
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_over[['annual_sell_quantity', 'annual_product_price', 'annual_unit_cost', 'lead_time']], df_over['class'], test_size=0.2, random_state=1) # 80% training and 20% test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRecX1byBO7z"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Standard Scalling the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train = df_over[['annual_sell_quantity', 'annual_product_price', 'annual_unit_cost', 'lead_time']]\n",
        "y_train = df_over['class']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFn4OiR9BO7z"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Assuming you have your features (X) and labels (y) ready\n",
        "# Replace X and y with your actual feature and label data\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "train_acc_arr = np.empty((10, 1))\n",
        "test_acc_arr = np.empty((10, 1))\n",
        "f1_arr = np.empty((10, 1))\n",
        "precision_arr = np.empty((10, 1))\n",
        "recall_arr = np.empty((10, 1))\n",
        "cv_acc_arr = np.empty((10, 1))\n",
        "cnf_arr = []\n",
        "x = 0\n",
        "\n",
        "max_classes = len(np.unique(y))  # Assuming y contains class labels\n",
        "\n",
        "for train_index, test_index in kf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model_ = SVC(kernel='poly', gamma=0.1, C=1.0, tol=1e-5, verbose=1, max_iter=2500).fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = model_.predict(X_train)\n",
        "    y_test_pred = model_.predict(X_test)\n",
        "\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "    precision = precision_score(y_test, y_test_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "    print('Train Accuracy : {:.4f}'.format(train_acc))\n",
        "    print('Test Accuracy  : {:.4f}'.format(test_acc))\n",
        "    print('SVC f1-score   : {:.4f}'.format(f1))\n",
        "    print('SVC precision  : {:.4f}'.format(precision))\n",
        "    print('SVC recall     : {:.4f}'.format(recall))\n",
        "    print(\"\\n\", classification_report(y_test, y_test_pred))\n",
        "\n",
        "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "    # Zero-pad the confusion matrix to ensure consistent shape\n",
        "    cnf_matrix = np.pad(cnf_matrix, ((0, max_classes - cnf_matrix.shape[0]), (0, max_classes - cnf_matrix.shape[1])))\n",
        "    cnf_arr.append(cnf_matrix)\n",
        "    train_acc_arr[x] = train_acc\n",
        "    test_acc_arr[x] = test_acc\n",
        "    f1_arr[x] = f1\n",
        "    precision_arr[x] = precision\n",
        "    recall_arr[x] = recall\n",
        "\n",
        "    # Calculate cross-validated accuracy\n",
        "    cv_acc = cross_val_score(model_, X, y, cv=kf, scoring='accuracy').mean()\n",
        "    cv_acc_arr[x] = cv_acc\n",
        "    print('Cross-Validated Accuracy: {:.4f}'.format(cv_acc))\n",
        "    print(\"\\n-----------------------------\\n\")\n",
        "\n",
        "    x = x + 1\n",
        "\n",
        "# Calculate and plot the total confusion matrix in percentage\n",
        "svc_total_cnf_matrix = np.sum(cnf_arr, axis=0)\n",
        "svc_total_cnf_matrix_percentage = svc_total_cnf_matrix / svc_total_cnf_matrix.sum(axis=1, keepdims=True) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(svc_total_cnf_matrix_percentage, annot=True, fmt='.2f', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('SVC Confusion Matrix (Percentage)')\n",
        "plt.show()\n",
        "\n",
        "print(\"%0.4f weighted f1 score with a standard deviation of %0.4f\" % (f1_arr.mean(), f1_arr.std()))\n",
        "print(\"%0.4f weighted precision with a standard deviation of %0.4f\" % (precision_arr.mean(), precision_arr.std()))\n",
        "print(\"%0.4f weighted recall with a standard deviation of %0.4f\" % (recall_arr.mean(), recall_arr.std()))\n",
        "print(\"%0.4f train accuracy with a standard deviation of %0.4f\" % (train_acc_arr.mean(), train_acc_arr.std()))\n",
        "print(\"%0.4f test accuracy with a standard deviation of %0.4f\" % (test_acc_arr.mean(), test_acc_arr.std()))\n",
        "print(\"%0.4f cross-validated accuracy with a standard deviation of %0.4f\" % (cv_acc_arr.mean(), cv_acc_arr.std()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kruAzI9DBO7z"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import KFold, cross_val_score\n",
        "# from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "# import numpy as np\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
        "# from sklearn.metrics import r2_score, roc_auc_score, roc_curve, classification_report\n",
        "# from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "\n",
        "# model_ = SVC(kernel='poly',gamma=0.1, C=1.0, tol=1e-5, verbose=1,max_iter=2500).fit(X_train, y_train)\n",
        "\n",
        "# kf = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "# train_acc_arr = np.empty((10, 1))\n",
        "# test_acc_arr = np.empty((10, 1))\n",
        "# f1_arr = np.empty((10, 1))\n",
        "# cv_acc_arr = np.empty((10, 1))\n",
        "# cnf_arr = []\n",
        "# x = 0\n",
        "\n",
        "# for train_index, test_index in kf.split(X, y):\n",
        "#     X_train, X_test = X[train_index], X[test_index]\n",
        "#     y_train, y_test = y[train_index], y[test_index]\n",
        "#     model_.fit(X_train, y_train)\n",
        "#     y_train_pred = model_.predict(X_train)\n",
        "#     y_test_pred = model_.predict(X_test)\n",
        "\n",
        "#     train_acc = accuracy_score(y_train, y_train_pred)\n",
        "#     test_acc = accuracy_score(y_test, y_test_pred)\n",
        "#     f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "#     print('Train Accuracy: {:.4f}'.format(train_acc))\n",
        "#     print('Test Accuracy : {:.4f}'.format(test_acc))\n",
        "#     print('SVC f1-score  : {:.4f}'.format(f1))\n",
        "#     print('SVC precision : {:.4f}'.format(precision_score(y_test, y_test_pred, average='weighted')))\n",
        "#     print('SVC recall    : {:.4f}'.format(recall_score(y_test, y_test_pred, average='weighted')))\n",
        "#     print(\"\\n\", classification_report(y_test, y_test_pred))\n",
        "\n",
        "#     cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "#     train_acc_arr[x] = train_acc\n",
        "#     test_acc_arr[x] = test_acc\n",
        "#     f1_arr[x] = f1\n",
        "\n",
        "#     # Calculate cross-validated accuracy\n",
        "#     cv_acc = cross_val_score(model_, X, y, cv=kf, scoring='accuracy').mean()\n",
        "#     cv_acc_arr[x] = cv_acc\n",
        "#     print('Cross-Validated Accuracy: {:.4f}'.format(cv_acc))\n",
        "#     print(\"\\n-----------------------------\\n\")\n",
        "\n",
        "#     x = x + 1\n",
        "\n",
        "# print(\"%0.4f weighted f1 score with a standard deviation of %0.4f\" % (f1_arr.mean(), f1_arr.std()))\n",
        "# print(\"%0.4f train accuracy with a standard deviation of %0.4f\" % (train_acc_arr.mean(), train_acc_arr.std()))\n",
        "# print(\"%0.4f test accuracy with a standard deviation of %0.4f\" % (test_acc_arr.mean(), test_acc_arr.std()))\n",
        "# print(\"%0.4f cross-validated accuracy with a standard deviation of %0.4f\" % (cv_acc_arr.mean(), cv_acc_arr.std()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qP_9FC1BO70"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1K-il0OBO70"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Your data (X, y) and KFold definition here\n",
        "\n",
        "# Create KNN model\n",
        "model_ = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "train_acc_arr = np.empty((10, 1))\n",
        "test_acc_arr = np.empty((10, 1))\n",
        "f1_arr = np.empty((10, 1))\n",
        "precision_arr = np.empty((10, 1))\n",
        "recall_arr = np.empty((10, 1))\n",
        "cv_acc_arr = np.empty((10, 1))\n",
        "cnf_matrix = []\n",
        "\n",
        "for x, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the KNN model on the training data\n",
        "    model_.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the training and test sets\n",
        "    y_train_pred = model_.predict(X_train)\n",
        "    y_test_pred = model_.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "    precision = precision_score(y_test, y_test_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "    print('Train Accuracy : {:.4f}'.format(train_acc))\n",
        "    print('Test Accuracy  : {:.4f}'.format(test_acc))\n",
        "    print('KNN f1-score   : {:.4f}'.format(f1))\n",
        "    print('KNN precision  : {:.4f}'.format(precision))\n",
        "    print('KNN recall     : {:.4f}'.format(recall))\n",
        "    print(\"\\n\", classification_report(y_test, y_test_pred))\n",
        "\n",
        "    cnf_matrix.append(confusion_matrix(y_test, y_test_pred))\n",
        "    train_acc_arr[x] = train_acc\n",
        "    test_acc_arr[x] = test_acc\n",
        "    f1_arr[x] = f1\n",
        "    precision_arr[x] = precision\n",
        "    recall_arr[x] = recall\n",
        "\n",
        "    # Calculate cross-validated accuracy\n",
        "    cv_acc = cross_val_score(model_, X, y, cv=kf, scoring='accuracy').mean()\n",
        "    cv_acc_arr[x] = cv_acc\n",
        "    print('Cross-Validated Accuracy: {:.4f}'.format(cv_acc))\n",
        "    print(\"\\n-----------------------------\\n\")\n",
        "\n",
        "# Summing up confusion matrices\n",
        "max_rows = max(matrix.shape[0] for matrix in cnf_matrix)\n",
        "max_cols = max(matrix.shape[1] for matrix in cnf_matrix)\n",
        "\n",
        "knn_total_cnf_matrix = np.zeros((max_rows, max_cols), dtype=int)\n",
        "\n",
        "for matrix in cnf_matrix:\n",
        "    knn_total_cnf_matrix[:matrix.shape[0], :matrix.shape[1]] += matrix\n",
        "\n",
        "knn_total_cnf_matrix_percentage = knn_total_cnf_matrix / knn_total_cnf_matrix.sum(axis=1, keepdims=True) * 100\n",
        "\n",
        "# Plotting the total confusion matrix as percentages\n",
        "plt.figure(figsize=(8, 6))\n",
        "# sns.heatmap(knn_total_cnf_matrix / knn_total_cnf_matrix.sum(axis=1)[:, None], annot=True, fmt='.2%', cmap='Blues', cbar=False)\n",
        "sns.heatmap(knn_total_cnf_matrix_percentage, annot=True, fmt='.2f', cmap='Blues', cbar=False)\n",
        "plt.title('KNN Confusion Matrix (Percentage)')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Rest of the code for printing summary statistics\n",
        "print(\"%0.4f weighted f1 score with a standard deviation of %0.4f\" % (f1_arr.mean(), f1_arr.std()))\n",
        "print(\"%0.4f weighted precision with a standard deviation of %0.4f\" % (precision_arr.mean(), precision_arr.std()))\n",
        "print(\"%0.4f weighted recall with a standard deviation of %0.4f\" % (recall_arr.mean(), recall_arr.std()))\n",
        "print(\"%0.4f train accuracy with a standard deviation of %0.4f\" % (train_acc_arr.mean(), train_acc_arr.std()))\n",
        "print(\"%0.4f test accuracy with a standard deviation of %0.4f\" % (test_acc_arr.mean(), test_acc_arr.std()))\n",
        "print(\"%0.4f cross-validated accuracy with a standard deviation of %0.4f\" % (cv_acc_arr.mean(), cv_acc_arr.std()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I557J1EABO70"
      },
      "outputs": [],
      "source": [
        "n = len(cnf_matrix)\n",
        "ncols = 2\n",
        "nrows = n // ncols + (n % ncols > 0)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 20))\n",
        "\n",
        "# Flatten the axes array and remove unused ones\n",
        "axes = axes.flatten()\n",
        "for ax in axes[n:]:\n",
        "    fig.delaxes(ax)\n",
        "\n",
        "for i, cm in enumerate(cnf_matrix):\n",
        "    ax = axes[i]\n",
        "    sns.heatmap(cm, annot=True, ax=ax, fmt='.2f', cmap='Blues')\n",
        "    ax.set_title(f'Confusion Matrix for Fold {i+1}')\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('True')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS3-6_ARBO70"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import KFold, cross_val_score\n",
        "# from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# import numpy as np\n",
        "\n",
        "# # Create KNN model\n",
        "# model_ = KNeighborsClassifier(n_neighbors=3)  # You can adjust the number of neighbors (n_neighbors) as needed\n",
        "\n",
        "# kf = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "# train_acc_arr = np.empty((10, 1))\n",
        "# test_acc_arr = np.empty((10, 1))\n",
        "# f1_arr = np.empty((10, 1))\n",
        "# cv_acc_arr = np.empty((10, 1))\n",
        "# cnf_matrix = []\n",
        "# x = 0\n",
        "\n",
        "# for train_index, test_index in kf.split(X, y):\n",
        "#     X_train, X_test = X[train_index], X[test_index]\n",
        "#     y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "#     # Fit the KNN model on the training data\n",
        "#     model_.fit(X_train, y_train)\n",
        "\n",
        "#     # Predictions on the training and test sets\n",
        "#     y_train_pred = model_.predict(X_train)\n",
        "#     y_test_pred = model_.predict(X_test)\n",
        "\n",
        "#     # Calculate metrics\n",
        "#     train_acc = accuracy_score(y_train, y_train_pred)\n",
        "#     test_acc = accuracy_score(y_test, y_test_pred)\n",
        "#     f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "#     print('Train Accuracy: {:.4f}'.format(train_acc))\n",
        "#     print('Test Accuracy : {:.4f}'.format(test_acc))\n",
        "#     print('KNN f1-score  : {:.4f}'.format(f1))\n",
        "#     print('KNN precision : {:.4f}'.format(precision_score(y_test, y_test_pred, average='weighted')))\n",
        "#     print('KNN recall    : {:.4f}'.format(recall_score(y_test, y_test_pred, average='weighted')))\n",
        "#     print(\"\\n\", classification_report(y_test, y_test_pred))\n",
        "\n",
        "#     cnf_matrix.append(confusion_matrix(y_test, y_test_pred))\n",
        "#     train_acc_arr[x] = train_acc\n",
        "#     test_acc_arr[x] = test_acc\n",
        "#     f1_arr[x] = f1\n",
        "\n",
        "#     # Calculate cross-validated accuracy\n",
        "#     cv_acc = cross_val_score(model_, X, y, cv=kf, scoring='accuracy').mean()\n",
        "#     cv_acc_arr[x] = cv_acc\n",
        "#     print('Cross-Validated Accuracy: {:.4f}'.format(cv_acc))\n",
        "#     print(\"\\n-----------------------------\\n\")\n",
        "\n",
        "#     x = x + 1\n",
        "\n",
        "# print(\"%0.4f weighted f1 score with a standard deviation of %0.4f\" % (f1_arr.mean(), f1_arr.std()))\n",
        "# print(\"%0.4f train accuracy with a standard deviation of %0.4f\" % (train_acc_arr.mean(), train_acc_arr.std()))\n",
        "# print(\"%0.4f test accuracy with a standard deviation of %0.4f\" % (test_acc_arr.mean(), test_acc_arr.std()))\n",
        "# print(\"%0.4f cross-validated accuracy with a standard deviation of %0.4f\" % (cv_acc_arr.mean(), cv_acc_arr.std()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykxq6ylvBO70"
      },
      "outputs": [],
      "source": [
        "n = len(cnf_matrix)\n",
        "ncols = 2\n",
        "nrows = n // ncols + (n % ncols > 0)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 20))\n",
        "\n",
        "# Flatten the axes array and remove unused ones\n",
        "axes = axes.flatten()\n",
        "for ax in axes[n:]:\n",
        "    fig.delaxes(ax)\n",
        "\n",
        "for i, cm in enumerate(cnf_matrix):\n",
        "    ax = axes[i]\n",
        "    sns.heatmap(cm, annot=True, ax=ax, fmt='.2f', cmap='Blues')\n",
        "    ax.set_title(f'Confusion Matrix for Fold {i+1}')\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('True')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_1NzcxOBO70"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming you have your features (X) and labels (y) ready\n",
        "# Replace X and y with your actual feature and label data\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "train_acc_arr = np.empty((10, 1))\n",
        "test_acc_arr = np.empty((10, 1))\n",
        "f1_arr = np.empty((10, 1))\n",
        "precision_arr = np.empty((10, 1))\n",
        "recall_arr = np.empty((10, 1))\n",
        "cv_acc_arr = np.empty((10, 1))\n",
        "cnf_arr = []\n",
        "x = 0\n",
        "\n",
        "max_classes = len(np.unique(y))  # Assuming y contains class labels\n",
        "\n",
        "model_ = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "for train_index, test_index in kf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the Random Forest model on the training data\n",
        "    model_.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the training and test sets\n",
        "    y_train_pred = model_.predict(X_train)\n",
        "    y_test_pred = model_.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    test_acc = accuracy_score(y_test, y_test_pred)\n",
        "    f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "    precision = precision_score(y_test, y_test_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "    print('Train Accuracy : {:.4f}'.format(train_acc))\n",
        "    print('Test Accuracy  : {:.4f}'.format(test_acc))\n",
        "    print('RF f1-score    : {:.4f}'.format(f1))\n",
        "    print('RF precision   : {:.4f}'.format(precision))\n",
        "    print('RF recall      : {:.4f}'.format(recall))\n",
        "    print(\"\\n\", classification_report(y_test, y_test_pred))\n",
        "\n",
        "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "    # Zero-pad the confusion matrix to ensure consistent shape\n",
        "    cnf_matrix = np.pad(cnf_matrix, ((0, max_classes - cnf_matrix.shape[0]), (0, max_classes - cnf_matrix.shape[1])))\n",
        "    cnf_arr.append(cnf_matrix)\n",
        "    train_acc_arr[x] = train_acc\n",
        "    test_acc_arr[x] = test_acc\n",
        "    f1_arr[x] = f1\n",
        "    precision_arr[x] = precision\n",
        "    recall_arr[x] = recall\n",
        "\n",
        "    # Calculate cross-validated accuracy\n",
        "    cv_acc = cross_val_score(model_, X, y, cv=kf, scoring='accuracy').mean()\n",
        "    cv_acc_arr[x] = cv_acc\n",
        "    print('Cross-Validated Accuracy: {:.4f}'.format(cv_acc))\n",
        "    print(\"\\n-----------------------------\\n\")\n",
        "\n",
        "    x = x + 1\n",
        "\n",
        "# Summing up confusion matrices\n",
        "max_rows = max(matrix.shape[0] for matrix in cnf_arr)\n",
        "max_cols = max(matrix.shape[1] for matrix in cnf_arr)\n",
        "\n",
        "rf_total_cnf_matrix = np.zeros((max_rows, max_cols), dtype=int)\n",
        "\n",
        "for matrix in cnf_arr:\n",
        "    rf_total_cnf_matrix[:matrix.shape[0], :matrix.shape[1]] += matrix\n",
        "\n",
        "# Plotting the total confusion matrix as percentages\n",
        "rf_total_cnf_matrix_percentage = rf_total_cnf_matrix / rf_total_cnf_matrix.sum(axis=1, keepdims=True) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(rf_total_cnf_matrix_percentage, annot=True, fmt='.2f', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Random Forest Confusion Matrix (Percentage)')\n",
        "plt.show()\n",
        "\n",
        "# Rest of the code for printing summary statistics\n",
        "print(\"%0.4f weighted f1 score with a standard deviation of %0.4f\" % (f1_arr.mean(), f1_arr.std()))\n",
        "print(\"%0.4f weighted precision with a standard deviation of %0.4f\" % (precision_arr.mean(), precision_arr.std()))\n",
        "print(\"%0.4f weighted recall with a standard deviation of %0.4f\" % (recall_arr.mean(), recall_arr.std()))\n",
        "print(\"%0.4f train accuracy with a standard deviation of %0.4f\" % (train_acc_arr.mean(), train_acc_arr.std()))\n",
        "print(\"%0.4f test accuracy with a standard deviation of %0.4f\" % (test_acc_arr.mean(), test_acc_arr.std()))\n",
        "print(\"%0.4f cross-validated accuracy with a standard deviation of %0.4f\" % (cv_acc_arr.mean(), cv_acc_arr.std()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2XoQHCNBO71"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import KFold, cross_val_score\n",
        "# from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# import numpy as np\n",
        "\n",
        "# # Create Random Forest model\n",
        "# model_ = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust the number of estimators (n_estimators) as needed\n",
        "\n",
        "# kf = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "# train_acc_arr = np.empty((10, 1))\n",
        "# test_acc_arr = np.empty((10, 1))\n",
        "# f1_arr = np.empty((10, 1))\n",
        "# cv_acc_arr = np.empty((10, 1))\n",
        "# cnf_matrix = []\n",
        "# x = 0\n",
        "\n",
        "# for train_index, test_index in kf.split(X, y):\n",
        "#     X_train, X_test = X[train_index], X[test_index]\n",
        "#     y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "#     # Fit the Random Forest model on the training data\n",
        "#     model_.fit(X_train, y_train)\n",
        "\n",
        "#     # Predictions on the training and test sets\n",
        "#     y_train_pred = model_.predict(X_train)\n",
        "#     y_test_pred = model_.predict(X_test)\n",
        "\n",
        "#     # Calculate metrics\n",
        "#     train_acc = accuracy_score(y_train, y_train_pred)\n",
        "#     test_acc = accuracy_score(y_test, y_test_pred)\n",
        "#     f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "#     print('Train Accuracy: {:.4f}'.format(train_acc))\n",
        "#     print('Test Accuracy : {:.4f}'.format(test_acc))\n",
        "#     print('Random Forest f1-score  : {:.4f}'.format(f1))\n",
        "#     print('Random Forest precision : {:.4f}'.format(precision_score(y_test, y_test_pred, average='weighted')))\n",
        "#     print('Random Forest recall    : {:.4f}'.format(recall_score(y_test, y_test_pred, average='weighted')))\n",
        "#     print(\"\\n\", classification_report(y_test, y_test_pred))\n",
        "\n",
        "#     cnf_matrix.append(confusion_matrix(y_test, y_test_pred))\n",
        "#     train_acc_arr[x] = train_acc\n",
        "#     test_acc_arr[x] = test_acc\n",
        "#     f1_arr[x] = f1\n",
        "\n",
        "#     # Calculate cross-validated accuracy\n",
        "#     cv_acc = cross_val_score(model_, X, y, cv=kf, scoring='accuracy').mean()\n",
        "#     cv_acc_arr[x] = cv_acc\n",
        "#     print('Cross-Validated Accuracy: {:.4f}'.format(cv_acc))\n",
        "#     print(\"\\n-----------------------------\\n\")\n",
        "\n",
        "#     x = x + 1\n",
        "\n",
        "# print(\"%0.4f weighted f1 score with a standard deviation of %0.4f\" % (f1_arr.mean(), f1_arr.std()))\n",
        "# print(\"%0.4f train accuracy with a standard deviation of %0.4f\" % (train_acc_arr.mean(), train_acc_arr.std()))\n",
        "# print(\"%0.4f test accuracy with a standard deviation of %0.4f\" % (test_acc_arr.mean(), test_acc_arr.std()))\n",
        "# print(\"%0.4f cross-validated accuracy with a standard deviation of %0.4f\" % (cv_acc_arr.mean(), cv_acc_arr.std()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svCT1e1qBO71"
      },
      "outputs": [],
      "source": [
        "n = len(cnf_matrix)\n",
        "ncols = 2\n",
        "nrows = n // ncols + (n % ncols > 0)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 20))\n",
        "\n",
        "# Flatten the axes array and remove unused ones\n",
        "axes = axes.flatten()\n",
        "for ax in axes[n:]:\n",
        "    fig.delaxes(ax)\n",
        "\n",
        "for i, cm in enumerate(cnf_matrix):\n",
        "    ax = axes[i]\n",
        "    sns.heatmap(cm, annot=True, ax=ax, fmt='.2f', cmap='Blues')\n",
        "    ax.set_title(f'Confusion Matrix for Fold {i+1}')\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('True')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbG6zyPABO71"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming you have the matrices rf_total_cnf_matrix_percentage, knn_total_cnf_matrix_percentage, and svc_total_cnf_matrix_percentage\n",
        "\n",
        "# Create a figure and subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
        "\n",
        "# Define a custom color map\n",
        "# Plot rf_total_cnf_matrix_percentage with annotations\n",
        "im_rf = axes[0].imshow(rf_total_cnf_matrix_percentage, cmap='Blues')\n",
        "for i in range(rf_total_cnf_matrix_percentage.shape[0]):\n",
        "    for j in range(rf_total_cnf_matrix_percentage.shape[1]):\n",
        "        axes[0].text(j, i, f'{rf_total_cnf_matrix_percentage[i, j]:.2f}%', ha='center', va='center', color='black')\n",
        "\n",
        "axes[0].set_title('Random Forest Confusion Matrix (Percentage)')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('True')\n",
        "fig.colorbar(im_rf, ax=axes[0])\n",
        "\n",
        "# Plot knn_total_cnf_matrix_percentage with annotations\n",
        "im_knn = axes[1].imshow(knn_total_cnf_matrix_percentage, cmap='Reds')\n",
        "for i in range(knn_total_cnf_matrix_percentage.shape[0]):\n",
        "    for j in range(knn_total_cnf_matrix_percentage.shape[1]):\n",
        "        axes[1].text(j, i, f'{knn_total_cnf_matrix_percentage[i, j]:.2f}%', ha='center', va='center', color='black')\n",
        "\n",
        "axes[1].set_title('KNN Confusion Matrix (Percentage)')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('True')\n",
        "fig.colorbar(im_knn, ax=axes[1])\n",
        "\n",
        "# Plot svc_total_cnf_matrix_percentage with annotations\n",
        "im_svc = axes[2].imshow(svc_total_cnf_matrix_percentage, cmap='Greens')\n",
        "for i in range(svc_total_cnf_matrix_percentage.shape[0]):\n",
        "    for j in range(svc_total_cnf_matrix_percentage.shape[1]):\n",
        "        axes[2].text(j, i, f'{svc_total_cnf_matrix_percentage[i, j]:.2f}%', ha='center', va='center', color='black')\n",
        "\n",
        "axes[2].set_title('SVC Confusion Matrix (Percentage)')\n",
        "axes[2].set_xlabel('Predicted')\n",
        "axes[2].set_ylabel('True')\n",
        "fig.colorbar(im_svc, ax=axes[2])\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtYbsnxKBO71"
      },
      "outputs": [],
      "source": [
        "rf_total_cnf_matrix_percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS7-8yyoBO71"
      },
      "outputs": [],
      "source": [
        "knn_total_cnf_matrix_percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uU45xpnBO72"
      },
      "outputs": [],
      "source": [
        "svc_total_cnf_matrix_percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5pd4iOnBO72"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}